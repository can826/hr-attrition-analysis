```markdown
# ğŸ”® HR Attrition Prediction Model

Eine Machine Learning LÃ¶sung zur Vorhersage von Mitarbeiterfluktuation mit Python - Demonstration der praktischen Anwendung von Data Science im HR-Bereich.

## ğŸ“‹ Inhaltsverzeichnis

- [Business Problem](#-business-problem)
- [Technische Implementierung](#-technische-implementierung)
- [Datenanalyse](#-datenanalyse)
- [Machine Learning Pipeline](#-machine-learning-pipeline)
- [Ergebnisse](#-ergebnisse)
- [Integration in HR-Systeme](#-integration-in-hr-systeme)
- [Installation & Nutzung](#-installation--nutzung)
- [Projektstruktur](#-projektstruktur)

## ğŸ¯ Business Problem

Mitarbeiterfluktuation ist eine der grÃ¶ÃŸten Herausforderungen im modernen HR-Management:

- **Kosten**: Jede KÃ¼ndigung kostet durchschnittlich 50.000â‚¬ (Recruiting, Einarbeitung, ProduktivitÃ¤tsverlust)
- **Reaktiv statt Proaktiv**: Traditionelle HR-Metriken erkennen Probleme erst, wenn es zu spÃ¤t ist
- **Fehlende Datennutzung**: Wertvolle Mitarbeiterdaten werden nicht fÃ¼r Vorhersagen genutzt

**LÃ¶sung**: Ein datengetriebenes FrÃ¼hwarnsystem, das KÃ¼ndigungsrisiken vorhersagt und konkrete Handlungsempfehlungen liefert.

## ğŸ› ï¸ Technische Implementierung

### Tech Stack

| Technologie | Version | Verwendungszweck |
|------------|---------|------------------|
| Python | 3.8+ | Programmiersprache |
| pandas | 1.5.3 | Datenmanipulation und -analyse |
| scikit-learn | 1.2.2 | Machine Learning Algorithmen |
| numpy | 1.24.3 | Numerische Berechnungen |
| matplotlib | 3.7.1 | Datenvisualisierung |
| seaborn | 0.12.2 | Statistische Visualisierungen |
| scipy | 1.10.1 | Statistische Tests |

### Daten-Pipeline

```
Rohdaten (CSV)
    â†“
Datenbereinigung (pandas)
    â†“
Feature Engineering
    â†“
Statistische Analyse (scipy)
    â†“
Model Training (scikit-learn)
    â†“
Evaluation & Visualisierung
    â†“
Business Insights
```

## ğŸ“Š Datenanalyse

### Datensatz
- **1.470 MitarbeiterdatensÃ¤tze** mit 35 Features
- **Zielvariable**: Attrition (Ja/Nein)
- **Fluktuationsrate**: 16,1% (unbalancierter Datensatz)

### Feature Engineering

```python
# Neue Features zur besseren Vorhersage
TenureRatio = YearsAtCompany / TotalWorkingYears  # LoyalitÃ¤tsindikator
IncomeClass = pd.cut(MonthlyIncome, bins=[0, 3000, 7000, max])  # Gehaltsklassen
```

**Herausforderung**: Division durch Null bei BerufsanfÃ¤ngern â†’ NaN-Imputation mit 0

### Statistische Validierung

1. **Chi-Quadrat-Test**: Zusammenhang zwischen Ãœberstunden und KÃ¼ndigung
   - p-value < 0.001 â†’ Hochsignifikant
   
2. **T-Test**: Gehaltsunterschiede zwischen KÃ¼ndigern und Bleibenden
   - KÃ¼ndigende verdienen durchschnittlich weniger (p < 0.05)

## ğŸ¤– Machine Learning Pipeline

### Modellauswahl

**Warum Logistische Regression mit L1-Regularisierung?**
- **Interpretierbarkeit**: HR-Abteilungen mÃ¼ssen Entscheidungen verstehen kÃ¶nnen
- **Feature Selection**: L1 eliminiert unwichtige Features automatisch
- **Performance**: Bei strukturierten Tabellendaten oft besser als komplexe Modelle

### Implementierung

```python
# Datenaufteilung
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Hyperparameter-Optimierung
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'class_weight': ['balanced', None]
}

# Model Training mit Cross-Validation
grid_search = GridSearchCV(
    LogisticRegression(penalty='l1', solver='liblinear'),
    param_grid,
    cv=5,
    scoring='roc_auc'
)
```

### Evaluation Metriken

| Metrik | Wert | Interpretation |
|--------|------|----------------|
| **AUC-ROC** | 0.826 | Exzellente Diskriminierung zwischen Klassen |
| **Precision** | 0.72 | 72% der KÃ¼ndigungsvorhersagen sind korrekt |
| **Recall** | 0.41 | 41% der tatsÃ¤chlichen KÃ¼ndigungen werden erkannt |
| **F1-Score** | 0.52 | Balance zwischen Precision und Recall |

## ğŸ“ˆ Ergebnisse

### Top Risikofaktoren (Feature Importance)

```
1. OverTime_Yes            (+2.01) â†’ 7.5x hÃ¶heres KÃ¼ndigungsrisiko
2. BusinessTravel_Frequent (+1.95) â†’ 7.0x hÃ¶heres Risiko  
3. JobRole_Sales_Rep       (+1.95) â†’ 7.0x hÃ¶heres Risiko
```

### Schutzfaktoren

```
1. EducationField_Other    (-2.06) â†’ 87% geringeres Risiko
2. EducationField_Medical  (-1.29) â†’ 72% geringeres Risiko
```

### Business Impact

- **Identifizierte Hochrisikogruppe**: 71 Mitarbeiter (16% der Testdaten)
- **Potenzielle Kosteneinsparung**: 2,95 Mio. â‚¬/Jahr
- **ROI der MaÃŸnahmen**: 4:1 (Ãœberstunden-Reduktion)

### Visualisierungen

#### Modell-Performance
![ROC Curve](visualizations/figures/roc_curve.png)

#### Feature Importance Analyse
![Feature Importance](visualizations/figures/feature_importance.png)

#### Business Insights Dashboard
![Business Insights Dashboard](visualizations/figures/business_insights_dashboard.png)

## ğŸ”„ Integration in HR-Systeme

### Implementierungsoptionen

#### 1. Batch-Processing (Monatliche Reports)
```python
# Pseudocode fÃ¼r monatlichen Risk Report
def monthly_attrition_report():
    employees = load_current_employee_data()
    risk_scores = model.predict_proba(employees)[:, 1]
    high_risk = employees[risk_scores > 0.3]
    generate_report(high_risk)
    send_to_hr(high_risk)
```

#### 2. Real-Time API Integration
```python
# REST API Endpoint fÃ¼r Echtzeit-Scoring
@app.route('/api/attrition-risk', methods=['POST'])
def predict_attrition():
    employee_data = request.json
    risk_score = model.predict_proba([employee_data])[0, 1]
    return {'employee_id': employee_data['id'], 
            'risk_score': risk_score,
            'risk_level': 'high' if risk_score > 0.3 else 'low'}
```

#### 3. Dashboard Integration
- Export der Vorhersagen als CSV fÃ¼r Power BI/Tableau
- Direktanbindung Ã¼ber Python-Connector
- Automatisierte Alerts bei RisikoÃ¤nderungen

### Datenanforderungen

**Minimale Features fÃ¼r Vorhersage:**
- Ãœberstunden (Ja/Nein)
- GeschÃ¤ftsreisefrequenz
- Jobrolle
- Bildungshintergrund
- BetriebszugehÃ¶rigkeit

**Optionale Features fÃ¼r bessere Genauigkeit:**
- Gehaltsinformationen
- Zufriedenheitswerte
- Performance Ratings

## ğŸš€ Installation & Nutzung

### Voraussetzungen
- Python 3.8 oder hÃ¶her
- Git
- 4GB RAM (fÃ¼r Datenverarbeitung)

### Quick Start

```bash
# 1. Repository klonen
git clone https://github.com/can826/hr-attrition-analysis.git
cd hr-attrition-analysis

# 2. Virtuelle Umgebung erstellen (empfohlen)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Dependencies installieren
pip install -r requirements.txt

# 4. Jupyter Notebook starten
jupyter notebook

# 5. Notebook Ã¶ffnen
# Navigiere zu: notebooks/HR_Attrition_Analysis_Complete.ipynb
```

### Verwendung des trainierten Modells

```python
import pickle
import pandas as pd

# Modell laden (nach Training)
with open('models/attrition_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Neue Mitarbeiterdaten vorbereiten
new_employee = pd.DataFrame({
    'OverTime_Yes': [1],
    'BusinessTravel_Travel_Frequently': [1],
    # ... weitere Features
})

# Vorhersage
risk_probability = model.predict_proba(new_employee)[0, 1]
print(f"KÃ¼ndigungsrisiko: {risk_probability:.1%}")
```

## ğŸ“ Projektstruktur

```
hr-attrition-analysis/
â”‚
â”œâ”€â”€ data/                           # DatensÃ¤tze
â”‚   â””â”€â”€ HR_data.csv                # Rohdaten (1.470 Mitarbeiter)
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter Notebooks
â”‚   â””â”€â”€ HR_Attrition_Analysis_Complete.ipynb
â”‚
â”œâ”€â”€ visualizations/                # Generierte Grafiken
â”‚   â””â”€â”€ figures/
â”‚       â”œâ”€â”€ roc_curve.png
â”‚       â”œâ”€â”€ feature_importance.png
â”‚       â””â”€â”€ business_insights_dashboard.png
â”‚
â”œâ”€â”€ reports/                       # Dokumentation
â”‚   â””â”€â”€ executive_summary.md       # Management Summary
â”‚
â”‚
â”œâ”€â”€ .gitignore                     # Git Ignores
â”œâ”€â”€ README.md                      # Diese Datei
â””â”€â”€ requirements.txt               # Python Dependencies
```

## ğŸ” WeiterfÃ¼hrende Analysen

### MÃ¶gliche Erweiterungen
1. **Zeitreihenanalyse**: Saisonale KÃ¼ndigungsmuster erkennen
2. **Survival Analysis**: Vorhersage des KÃ¼ndigungszeitpunkts
3. **Clustering**: Mitarbeitertypen identifizieren
4. **Deep Learning**: Neural Networks fÃ¼r non-lineare Muster

### Limitationen
- Historische Daten reflektieren mÃ¶glicherweise nicht zukÃ¼nftige Trends
- Modell sollte regelmÃ¤ÃŸig mit neuen Daten neu trainiert werden
- Ethische Ãœberlegungen bei der Nutzung von Vorhersagen beachten

## ğŸ“ Kontakt

**Can Pascal Cevikkollu**  
| [GitHub](https://github.com/can826)

---